{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BHdMfFcnf_Ki"
   },
   "source": [
    "## Logistic Regression Modeling for Early Stage Diabetes Risk Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.1: Getting familiar with linear algebraic functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "- Create matrix of size 10*10 with random integer numbers\n",
    "- Compute the following linear algebric operations on the matrix using built in functions supported in Numpy, Scipy etc.\n",
    "  - Find inverse of the matrix and print it\n",
    "  - Calculate dot product of the matrix with same matrix in transpose A.AT\n",
    "  - Decompose the original matrix using eigen decomposition print the eigen values and eigen vectors\n",
    "  - Calculate jacobian matrix \n",
    "  - Calculate hessian matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.35590429  0.02953479  0.06968355 -1.470385   -0.35676455 -1.07727124\n",
      "   1.03857476 -1.66458255  2.64631575  0.20940638]\n",
      " [-0.46853732  0.94918764 -0.68219478 -0.80368534 -1.06894751  1.28953775\n",
      "  -0.2432069   0.02039012  0.27553714  0.13191232]\n",
      " [ 0.03877342  0.71651487 -1.19668935 -0.33831125  0.90517736  0.09604976\n",
      "  -0.07090145 -0.22444493  1.72852822 -1.97041863]\n",
      " [-0.68322704  0.27842696  0.97966739  2.22886606  0.07252684  1.11666324\n",
      "  -0.44635991  0.27725707  1.64099361  0.68326517]\n",
      " [-0.11891448  1.22145747  1.19029981 -2.11648935  0.34148235 -0.61240625\n",
      "   0.71777906 -0.60528111  0.33835995  1.84092284]\n",
      " [-0.28652256  0.76672991 -1.66549431  0.25557745  0.04885545  1.01047247\n",
      "   1.46539276  1.09980106 -1.03670144  2.26629357]\n",
      " [-0.67705638  1.20086983  1.2917641   0.97790034  1.20688518 -0.73275301\n",
      "  -1.06959129  0.32640495 -0.37605509  1.25481758]\n",
      " [-0.16863274 -0.1841613  -0.18244368 -0.41680261 -1.71881626  0.08043349\n",
      "  -0.54121281  0.20993064 -0.95994635 -0.24397324]\n",
      " [ 2.09734181  0.27509121  0.88733929  0.03521326 -1.00829311  0.29518699\n",
      "   1.48679455 -1.58044697 -2.30417862 -0.26359151]\n",
      " [-0.16732729  1.14537513 -1.41534955  1.07305288 -0.5272702   1.01754013\n",
      "  -0.89381434 -0.81721427  0.00662668  0.06850598]]\n"
     ]
    }
   ],
   "source": [
    "mat = np.random.randn(10, 10)\n",
    "mat.shape\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.59521063, -1.37423788,  0.49165748,  0.51333876,  1.13073357,\n",
       "         0.00484049, -0.83488061,  0.8158491 , -0.15167678,  0.55569845],\n",
       "       [-0.02468385, -0.17417291,  0.58280058,  0.19209337,  0.22708191,\n",
       "         0.20031459,  0.29030996,  0.58642584,  0.17629397, -0.0219142 ],\n",
       "       [ 0.04676621,  0.42247429, -0.10221447,  0.0846007 , -0.14682889,\n",
       "        -0.14569079,  0.24145698, -0.16651478,  0.1606853 , -0.37235128],\n",
       "       [ 0.05640582, -0.38774426,  0.15834678,  0.24238444, -0.08655092,\n",
       "         0.1431052 ,  0.08829464,  0.28674682,  0.0991086 ,  0.08812883],\n",
       "       [ 0.03296805,  0.60549476, -0.32087713, -0.38824392, -0.37911907,\n",
       "        -0.12995945,  0.23415889, -1.01698768, -0.01901896, -0.12067801],\n",
       "       [-0.00331735,  1.14381769, -0.50411398, -0.19151404, -0.45263193,\n",
       "        -0.19975492,  0.04168301, -1.02798439,  0.06272209, -0.19353326],\n",
       "       [ 0.28030864,  0.21956307,  0.16304956,  0.03054997, -0.34272012,\n",
       "         0.28922658,  0.22685861, -0.043804  ,  0.29175594, -0.44170119],\n",
       "       [-0.26654613, -0.46034838,  0.48974092,  0.33091505,  0.3311355 ,\n",
       "         0.242902  , -0.1063848 ,  0.75812462, -0.11797985, -0.25240148],\n",
       "       [-0.1584221 , -0.71533126,  0.34600477,  0.44710312,  0.59942354,\n",
       "         0.02030661, -0.46657209,  0.50407186, -0.17779984,  0.23184843],\n",
       "       [-0.16249094, -0.52945338, -0.18111636,  0.152692  ,  0.51308522,\n",
       "         0.04714818, -0.36840444,  0.12131025, -0.2121949 ,  0.39713314]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inverse of the matrix \n",
    "\n",
    "mat_inv = np.linalg.inv(mat)\n",
    "mat_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.19034151,  1.25994754,  4.41782436,  0.05733696,  6.9641253 ,\n",
       "        -3.76434799, -2.4221565 , -2.15302586, -4.76173749, -1.85986514],\n",
       "       [ 1.25994754,  5.19022752,  1.13550248,  0.14371472,  1.09849623,\n",
       "         2.72295696, -2.11639533,  2.143917  , -0.96022311,  3.35608417],\n",
       "       [ 4.41782436,  1.13550248,  9.8157504 , -0.12089314, -2.54508785,\n",
       "        -4.02210103, -3.14038347, -2.51457335, -4.89383064,  1.88862106],\n",
       "       [ 0.05733696,  0.14371472, -0.12089314, 11.15992976, -2.4641473 ,\n",
       "        -0.02274946,  4.31952892, -2.52081932, -5.21516953,  2.76642014],\n",
       "       [ 6.9641253 ,  1.09849623, -2.54508785, -2.4641473 , 12.27914778,\n",
       "         2.05253155,  3.09355   , -1.4655817 ,  1.30210186, -3.35863247],\n",
       "       [-3.76434799,  2.72295696, -4.02210103, -0.02274946,  2.05253155,\n",
       "        14.10037728,  0.55702547, -0.01819365,  0.62207406,  2.49990001],\n",
       "       [-2.4221565 , -2.11639533, -3.14038347,  4.31952892,  3.09355   ,\n",
       "         0.55702547,  9.48548636, -2.18134755, -2.91258437,  0.10056106],\n",
       "       [-2.15302586,  2.143917  , -2.51457335, -2.52081932, -1.4655817 ,\n",
       "        -0.01819365, -2.18134755,  4.54816351,  2.31564608,  0.90548889],\n",
       "       [-4.76173749, -0.96022311, -4.89383064, -5.21516953,  1.30210186,\n",
       "         0.62207406, -2.91258437,  2.31564608, 16.45400942, -0.49264307],\n",
       "       [-1.85986514,  3.35608417,  1.88862106,  2.76642014, -3.35863247,\n",
       "         2.49990001,  0.10056106,  0.90548889, -0.49264307,  7.27942144]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_dot = np.dot(mat, mat.T)\n",
    "mat_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.57532556+0.j          4.01896632+0.j         -2.63107973+0.j\n",
      " -1.01645421+2.31140452j -1.01645421-2.31140452j  2.07424542+1.28028453j\n",
      "  2.07424542-1.28028453j -0.52965048+0.870487j   -0.52965048-0.870487j\n",
      "  1.01323911+0.j        ]\n",
      "\n",
      "=======================================================\n",
      "\n",
      "[[ 0.63063103+0.j          0.21546761+0.j          0.58473046+0.j\n",
      "  -0.10211166-0.01530608j -0.10211166+0.01530608j -0.25255892+0.05963478j\n",
      "  -0.25255892-0.05963478j  0.62804124+0.j          0.62804124-0.j\n",
      "   0.42069038+0.j        ]\n",
      " [ 0.14191887+0.j         -0.24590119+0.j          0.23757235+0.j\n",
      "  -0.14165799+0.27200046j -0.14165799-0.27200046j  0.28073081-0.22550863j\n",
      "   0.28073081+0.22550863j  0.13744039+0.09410402j  0.13744039-0.09410402j\n",
      "  -0.39981681+0.j        ]\n",
      " [ 0.29406619+0.j          0.1817327 +0.j         -0.49109119+0.j\n",
      "  -0.24208944+0.05479684j -0.24208944-0.05479684j -0.04042206-0.14441471j\n",
      "  -0.04042206+0.14441471j -0.15280374-0.04771561j -0.15280374+0.04771561j\n",
      "  -0.27448098+0.j        ]\n",
      " [ 0.16348751+0.j         -0.51279158+0.j          0.22222353+0.j\n",
      "   0.08462249+0.1917779j   0.08462249-0.1917779j  -0.42782872+0.j\n",
      "  -0.42782872-0.j         -0.00089189+0.08416184j -0.00089189-0.08416184j\n",
      "   0.0274841 +0.j        ]\n",
      " [ 0.04165831+0.j          0.12237479+0.j          0.39052976+0.j\n",
      "   0.22929378-0.00992997j  0.22929378+0.00992997j  0.06526266-0.39548296j\n",
      "   0.06526266+0.39548296j -0.12947641-0.29207749j -0.12947641+0.29207749j\n",
      "   0.16142313+0.j        ]\n",
      " [ 0.02761747+0.j         -0.61297937+0.j         -0.23261968+0.j\n",
      "  -0.0567342 -0.53681198j -0.0567342 +0.53681198j  0.19137555-0.33517527j\n",
      "   0.19137555+0.33517527j -0.29653012-0.23681767j -0.29653012+0.23681767j\n",
      "   0.00879911+0.j        ]\n",
      " [-0.15103072+0.j         -0.12879396+0.j         -0.00135839+0.j\n",
      "   0.57799147+0.j          0.57799147-0.j         -0.05576016-0.20210873j\n",
      "  -0.05576016+0.20210873j -0.10146981+0.03378136j -0.10146981-0.03378136j\n",
      "  -0.26073608+0.j        ]\n",
      " [-0.08225937+0.j          0.02338023+0.j          0.27955774+0.j\n",
      "   0.05529393+0.20100972j  0.05529393-0.20100972j  0.34959593+0.21162624j\n",
      "   0.34959593-0.21162624j  0.35425617-0.070398j    0.35425617+0.070398j\n",
      "  -0.48565998+0.j        ]\n",
      " [-0.66095874+0.j          0.01728198+0.j         -0.00083707+0.j\n",
      "  -0.12756616-0.09867858j -0.12756616+0.09867858j -0.26090185-0.01266636j\n",
      "  -0.26090185+0.01266636j  0.30293098+0.05895434j  0.30293098-0.05895434j\n",
      "   0.1885265 +0.j        ]\n",
      " [-0.00435557+0.j         -0.43470894+0.j         -0.16222002+0.j\n",
      "  -0.01806097+0.20446175j -0.01806097-0.20446175j -0.08354135-0.04079526j\n",
      "  -0.08354135+0.04079526j  0.24824607+0.01622864j  0.24824607-0.01622864j\n",
      "   0.47068559+0.j        ]]\n"
     ]
    }
   ],
   "source": [
    "#eigen values and eigen vectors\n",
    "\n",
    "eig_val, eig_vector = np.linalg.eig(mat)\n",
    "print(eig_val)\n",
    "print(\"\\n=======================================================\\n\")\n",
    "print(eig_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "#calculate the jacobian matrix\n",
    "import numdifftools as nd\n",
    "\n",
    "f = lambda x : x ** 2\n",
    "\n",
    "mat_jacobian = nd.Jacobian(f)(mat)\n",
    "print(mat_jacobian.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function unary_to_nary.<locals>.nary_operator.<locals>.nary_f at 0x000001ECF56CD1F0>\n"
     ]
    }
   ],
   "source": [
    "#calculate the jacobian matrix\n",
    "from autograd import jacobian\n",
    "\n",
    "mat_jacobian = jacobian(mat)\n",
    "print(mat_jacobian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numdifftools in c:\\users\\vinee\\anaconda3\\lib\\site-packages (0.9.39)\n"
     ]
    }
   ],
   "source": [
    "#installing numdifftools\n",
    "!pip install numdifftools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autograd in c:\\users\\vinee\\anaconda3\\lib\\site-packages (1.3)\n",
      "Requirement already satisfied: future>=0.15.2 in c:\\users\\vinee\\anaconda3\\lib\\site-packages (from autograd) (0.18.2)\n",
      "Requirement already satisfied: numpy>=1.12 in c:\\users\\vinee\\anaconda3\\lib\\site-packages (from autograd) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "#installing autograd\n",
    "!pip install autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2]\n",
      " [ 1 -2]]\n",
      "[[ 3 -1]\n",
      " [ 3 -1]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2], [1,2]])\n",
    "b = np.array([[1, 1], [1, -1]])\n",
    "\n",
    "print(a * b) # elementwise product\n",
    "print(a @ b) # matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.2: Logistic Regression using newton method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1LWrifqkf_Kj"
   },
   "source": [
    "### Logistic regression\n",
    "Logistic regression uses an equation as the representation, very much like linear regression.\n",
    "\n",
    "Input values (x) are combined linearly using weights or coefficient values (referred to as W) to predict an output value (y). A key difference from linear regression is that the output value being modeled is a binary values (0 or 1) rather than a continuous value.<br>\n",
    "\n",
    "###  $\\hat{y}(w, x) = \\frac{1}{1+exp^{-(w_0 + w_1 * x_1 + ... + w_p * x_p)}}$\n",
    "\n",
    "#### Dataset\n",
    "The dataset is available at <strong>\"data/diabetes_data.csv\"</strong> in the respective challenge's repo.<br>\n",
    "<strong>Original Source:</strong> http://archive.ics.uci.edu/ml/machine-learning-databases/00529/diabetes_data_upload.csv. The dataset just got released in July 2020.<br><br>\n",
    "\n",
    "#### Features (X)\n",
    "\n",
    "1. Age                - Values ranging from 16-90\n",
    "2. Gender             - Binary value (Male/Female)\n",
    "3. Polyuria           - Binary value (Yes/No)\n",
    "4. Polydipsia         - Binary value (Yes/No)\n",
    "5. sudden weight loss - Binary value (Yes/No)\n",
    "6. weakness           - Binary value (Yes/No)\n",
    "7. Polyphagia         - Binary value (Yes/No)\n",
    "8. Genital thrush     - Binary value (Yes/No)\n",
    "9. visual blurring    - Binary value (Yes/No)\n",
    "10. Itching           - Binary value (Yes/No)\n",
    "11. Irritability      - Binary value (Yes/No)\n",
    "12. delayed healing   - Binary value (Yes/No)\n",
    "13. partial paresis   - Binary value (Yes/No)\n",
    "14. muscle stiffness  - Binary value (Yes/No)\n",
    "15. Alopecia          - Binary value (Yes/No)\n",
    "16. Obesity           - Binary value (Yes/No)\n",
    "\n",
    "#### Output/Target target (Y) \n",
    "17. class - Binary class (Positive/Negative)\n",
    "\n",
    "#### Objective\n",
    "To learn logistic regression and practice handling of both numerical and categorical features\n",
    "\n",
    "#### Tasks\n",
    "- Download, load the data and print first 5 and last 5 rows\n",
    "- Transform categorical features into numerical features. Use label encoding or any other suitable preprocessing technique\n",
    "- Since the age feature is in larger range, age column can be normalized into smaller scale (like 0 to 1) using different methods such as scaling, standardizing or any other suitable preprocessing technique (Example - sklearn.preprocessing.MinMaxScaler class)\n",
    "- Define X matrix (independent features) and y vector (target feature)\n",
    "- Split the dataset into 60% for training and rest 40% for testing (sklearn.model_selection.train_test_split function)\n",
    "- Train Logistic Regression Model on the training set (sklearn.linear_model.LogisticRegression class)\n",
    "- Use the trained model to predict on testing set\n",
    "- Print 'Accuracy' obtained on the testing dataset i.e. (sklearn.metrics.accuracy_score function)\n",
    "\n",
    "#### Further fun (will not be evaluated)\n",
    "- Plot loss curve (Loss vs number of iterations)\n",
    "- Preprocess data with different feature scaling methods (i.e. scaling, normalization, standardization, etc) and observe accuracies on both X_train and X_test\n",
    "- Training model on different train-test splits such as 60-40, 50-50, 70-30, 80-20, 90-10, 95-5 etc. and observe accuracies on both X_train and X_test\n",
    "- Shuffling of training samples with different *random seed values* in the train_test_split function. Check the model error for the testing data for each setup.\n",
    "- Print other classification metrics such as:\n",
    "    - classification report (sklearn.metrics.classification_report),\n",
    "    - confusion matrix (sklearn.metrics.confusion_matrix),\n",
    "    - precision, recall and f1 scores (sklearn.metrics.precision_recall_fscore_support)\n",
    "\n",
    "#### Helpful links\n",
    "- Scikit-learn documentation for logistic regression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "- How Logistic Regression works: https://machinelearningmastery.com/logistic-regression-for-machine-learning/\n",
    "- Feature Scaling: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- Training testing splitting: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "- Classification metrics in sklearn: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "- Use slack for doubts: https://join.slack.com/t/deepconnectai/shared_invite/zt-givlfnf6-~cn3SQ43k0BGDrG9_YOn4g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XqZrgW_if_Kq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Polyuria</th>\n",
       "      <th>Polydipsia</th>\n",
       "      <th>sudden weight loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>Polyphagia</th>\n",
       "      <th>Genital thrush</th>\n",
       "      <th>visual blurring</th>\n",
       "      <th>Itching</th>\n",
       "      <th>Irritability</th>\n",
       "      <th>delayed healing</th>\n",
       "      <th>partial paresis</th>\n",
       "      <th>muscle stiffness</th>\n",
       "      <th>Alopecia</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Gender Polyuria Polydipsia sudden weight loss weakness Polyphagia  \\\n",
       "0   40   Male       No        Yes                 No      Yes         No   \n",
       "1   58   Male       No         No                 No      Yes         No   \n",
       "2   41   Male      Yes         No                 No      Yes        Yes   \n",
       "3   45   Male       No         No                Yes      Yes        Yes   \n",
       "4   60   Male      Yes        Yes                Yes      Yes        Yes   \n",
       "\n",
       "  Genital thrush visual blurring Itching Irritability delayed healing  \\\n",
       "0             No              No     Yes           No             Yes   \n",
       "1             No             Yes      No           No              No   \n",
       "2             No              No     Yes           No             Yes   \n",
       "3            Yes              No     Yes           No             Yes   \n",
       "4             No             Yes     Yes          Yes             Yes   \n",
       "\n",
       "  partial paresis muscle stiffness Alopecia Obesity     class  \n",
       "0              No              Yes      Yes     Yes  Positive  \n",
       "1             Yes               No      Yes      No  Positive  \n",
       "2              No              Yes      Yes      No  Positive  \n",
       "3              No               No       No      No  Positive  \n",
       "4             Yes              Yes      Yes     Yes  Positive  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: DO NOT CHANGE THE VARIABLE NAME(S) IN THIS CELL\n",
    "# Load the data\n",
    "data = pd.read_csv('data/diabetes_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal Dataframe : \n",
      "Columns :  ['Age', 'Gender', 'Polyuria', 'Polydipsia', 'sudden weight loss', 'weakness', 'Polyphagia', 'Genital thrush', 'visual blurring', 'Itching', 'Irritability', 'delayed healing', 'partial paresis', 'muscle stiffness', 'Alopecia', 'Obesity', 'class']\n",
      "No. of rows :  520\n",
      "No. of columns :  17\n"
     ]
    }
   ],
   "source": [
    "print(\"Orginal Dataframe : \")\n",
    "print(\"Columns : \", list(data.columns))\n",
    "print(\"No. of rows : \", data.shape[0])\n",
    "print(\"No. of columns : \", data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjCRzhp_f_Kw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "# Handle categorical/binary columns\n",
    "categ = list(data.columns)\n",
    "categ.remove('Age')\n",
    "print(len(categ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Age is the only numerical variable.\n",
    "'Age' in categ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Male', 'Female'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      328\n",
       "Female    192\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets label encode remaining variables.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "data[categ] = data[categ].apply(le.fit_transform) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3aNK0lA1f_Kz"
   },
   "outputs": [],
   "source": [
    "# Normalize the age feature to [0, 1]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data.Age = scaler.fit_transform(pd.DataFrame(data.Age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqCVUtIUf_K3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Polyuria</th>\n",
       "      <th>Polydipsia</th>\n",
       "      <th>sudden weight loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>Polyphagia</th>\n",
       "      <th>Genital thrush</th>\n",
       "      <th>visual blurring</th>\n",
       "      <th>Itching</th>\n",
       "      <th>Irritability</th>\n",
       "      <th>delayed healing</th>\n",
       "      <th>partial paresis</th>\n",
       "      <th>muscle stiffness</th>\n",
       "      <th>Alopecia</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.324324</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.567568</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.337838</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.391892</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.594595</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Gender  Polyuria  Polydipsia  sudden weight loss  weakness  \\\n",
       "0  0.324324       1         0           1                   0         1   \n",
       "1  0.567568       1         0           0                   0         1   \n",
       "2  0.337838       1         1           0                   0         1   \n",
       "3  0.391892       1         0           0                   1         1   \n",
       "4  0.594595       1         1           1                   1         1   \n",
       "\n",
       "   Polyphagia  Genital thrush  visual blurring  Itching  Irritability  \\\n",
       "0           0               0                0        1             0   \n",
       "1           0               0                1        0             0   \n",
       "2           1               0                0        1             0   \n",
       "3           1               1                0        1             0   \n",
       "4           1               0                1        1             1   \n",
       "\n",
       "   delayed healing  partial paresis  muscle stiffness  Alopecia  Obesity  \\\n",
       "0                1                0                 1         1        1   \n",
       "1                0                1                 0         1        0   \n",
       "2                1                0                 1         1        0   \n",
       "3                1                0                 0         0        0   \n",
       "4                1                1                 1         1        1   \n",
       "\n",
       "   class  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final dataframe after label encoding and scaling.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Uc-BEzqf_K-"
   },
   "outputs": [],
   "source": [
    "# Define your X and y\n",
    "X = data.drop('class', axis = 1).values\n",
    "y = data['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X :  (520, 16)\n",
      "Type of X :  <class 'numpy.ndarray'>\n",
      "Shape of y :  (520,)\n",
      "Type of y :  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X : \", X.shape)\n",
    "print(\"Type of X : \", type(X))\n",
    "print(\"Shape of y : \", y.shape)\n",
    "print(\"Type of y : \", type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DIiMrIaajX-Q"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train :  (312, 16)\n",
      "Shape of y_train :  (312,)\n",
      "Shape of X_test :  (208, 16)\n",
      "Shape of y_test :  (208,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of X_train : \", X_train.shape)\n",
    "print(\"Shape of y_train : \", y_train.shape)\n",
    "print(\"Shape of X_test : \", X_test.shape)\n",
    "print(\"Shape of y_test : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, weights):\n",
    "    '''Predict class for X.\n",
    "    For the given dataset, predicted vector has only values 0/1\n",
    "    Args:\n",
    "        X : Numpy array (num_samples, num_features)\n",
    "        weights : Model weights for logistic regression\n",
    "    Returns:\n",
    "        Binary predictions : (num_samples,)\n",
    "    '''\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    z = np.dot(X, weights)\n",
    "    logits = sigmoid(z)\n",
    "    y_pred = logits.round()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "        '''Sigmoid function: f:R->(0,1)\n",
    "        Args:\n",
    "            z : A numpy array (num_samples,)\n",
    "        Returns:\n",
    "            A numpy array where sigmoid function applied to every element\n",
    "        '''\n",
    "        ### START CODE HERE\n",
    "        sig_z = 1 / (1 + np.exp(-z))\n",
    "        ### END CODE HERE\n",
    "        \n",
    "        assert (z.shape==sig_z.shape), 'Error in sigmoid implementation. Check carefully'\n",
    "        return sig_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    '''Calculate cross entropy loss\n",
    "    Note: Cross entropy is defined for multiple classes/labels as well\n",
    "    but for this dataset we only need binary cross entropy loss\n",
    "    Args:\n",
    "        y_true : Numpy array of true values (0/1) of size (num_samples,)\n",
    "        y_pred : Numpy array of predicted values (probabilites) of size (num_samples,)\n",
    "    Returns:\n",
    "        Cross entropy loss: A scalar value\n",
    "    '''\n",
    "    # Fix 0 values in y_pred\n",
    "    y_pred = np.maximum(np.full(y_pred.shape, 1e-7), np.minimum(np.full(y_pred.shape, 1-1e-7), y_pred))\n",
    "    \n",
    "    ### START CODE HERE\n",
    "    ce_loss = np.mean(- y_true * np.log(y_pred) - (1 - y_true) * np.log(1 - y_pred))\n",
    "    ### END CODE HERE_\n",
    "    \n",
    "    return ce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_optimization(X, y, max_iterations=25):\n",
    "    '''Implement netwon method for optimizing weights\n",
    "    Args:\n",
    "        X : Numpy array (num_samples, num_features)\n",
    "        max_iterations : Max iterations to update the weights\n",
    "    Returns:\n",
    "        Optimal weights (num_features,)\n",
    "    '''\n",
    "    num_samples = X.shape[0]\n",
    "    num_features = X.shape[1]\n",
    "    # Initialize random weights\n",
    "    weights = np.zeros(num_features,)\n",
    "    # Initialize losses\n",
    "    losses = []\n",
    "    \n",
    "    # Newton Method\n",
    "    for i in range(max_iterations):\n",
    "        # Predict/Calculate probabilties using sigmoid function\n",
    "        z = predict(X, weights)\n",
    "        y_pred = sigmoid(z)\n",
    "        \n",
    "        # Define gradient for J (cost function) i.e. cross entropy loss\n",
    "        gradient = (1 / num_samples) * np.dot(X.T, (y_pred - y))  \n",
    "        \n",
    "        # Define hessian matrix for cross entropy loss\n",
    "        hessian = (1 / num_samples) * X.T.dot(np.diag(y_pred * (1 - y_pred))).dot(X)\n",
    "        \n",
    "        # Update the model using hessian matrix and gradient computed\n",
    "        weights -= np.dot(np.linalg.pinv(hessian), gradient)\n",
    "        \n",
    "        # Calculate cross entropy loss\n",
    "        loss = cross_entropy_loss(y, y_pred)\n",
    "        # Append it\n",
    "        losses.append(loss)\n",
    "\n",
    "    return weights, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train weights\n",
    "weights, losses = newton_optimization(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.plot([i+1 for i in range(len(losses))], losses)\n",
    "plt.title(\"Loss curve\")\n",
    "plt.xlabel(\"Iteration num\")\n",
    "plt.ylabel(\"Cross entropy curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy in testing set by our model: 0.9086538461538461\n"
     ]
    }
   ],
   "source": [
    "our_model_test_acuracy = accuracy_score(y_test, predict(X_test, weights))\n",
    "\n",
    "print(f\"\\nAccuracy in testing set by our model: {our_model_test_acuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare with the scikit learn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qhvibx3Xf_LB"
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = LogisticRegression(solver='newton-cg', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ndXHgNLxf_LD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='newton-cg', verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model. Wait! We will complete this step for you ;)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oHOeLfjFjeNh"
   },
   "outputs": [],
   "source": [
    "# Predict on testing set X_test\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eE5g0uoYf_LG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy in testing set by sklearn model: 0.9375\n"
     ]
    }
   ],
   "source": [
    "# Print Accuracy on testing set\n",
    "sklearn_test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nAccuracy in testing set by sklearn model: {sklearn_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "task_2_logistic_diabetes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
